# -*- coding: utf-8 -*-
"""Untitled32.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11qZAuXE-irIt3SeSlJ4d1xj93XD6Bj7T
"""

import streamlit as st
import feedparser
from datetime import datetime, timedelta
import pandas as pd
import re
import urllib.parse
from io import BytesIO
from docx import Document
from docx.shared import RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.oxml.shared import OxmlElement, qn
import docx.opc.constants

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Buscador de Noticias",
    page_icon="üì∞",
    layout="wide"
)

# T√≠tulo y descripci√≥n
st.title("üì∞ Buscador de Noticias en Google News")
st.markdown("Este programa busca noticias seg√∫n tus preferencias. Para resultados m√°s precisos, s√© espec√≠fico en tu b√∫squeda.")

def limpiar_texto(texto):
    texto = re.sub('<[^<]+?>', '', texto)
    texto = re.sub('\s+', ' ', texto).strip()
    return texto

def agregar_hiperv√≠nculo(paragraph, url, texto):
    part = paragraph.part
    r_id = part.relate_to(url, docx.opc.constants.RELATIONSHIP_TYPE.HYPERLINK, is_external=True)

    hyperlink = OxmlElement('w:hyperlink')
    hyperlink.set(qn('r:id'), r_id)

    new_run = OxmlElement('w:r')
    rPr = OxmlElement('w:rPr')

    u = OxmlElement('w:u')
    u.set(qn('w:val'), 'single')
    color = OxmlElement('w:color')
    color.set(qn('w:val'), '0000FF')

    rPr.append(u)
    rPr.append(color)
    new_run.append(rPr)

    t = OxmlElement('w:t')
    t.text = texto
    new_run.append(t)

    hyperlink.append(new_run)
    paragraph._p.append(hyperlink)

def crear_documento_word(df_noticias, tema, periodo_tiempo, terminos_busqueda):
    doc = Document()

    titulo = doc.add_heading(f'Noticias sobre: {tema}', 0)
    titulo.alignment = WD_ALIGN_PARAGRAPH.CENTER

    fecha_parrafo = doc.add_paragraph()
    fecha_parrafo.alignment = WD_ALIGN_PARAGRAPH.CENTER
    fecha_parrafo.add_run(f'B√∫squeda realizada el {datetime.now().strftime("%d/%m/%Y %H:%M")}')

    terminos_parrafo = doc.add_paragraph()
    terminos_parrafo.alignment = WD_ALIGN_PARAGRAPH.CENTER
    terminos_parrafo.add_run(f'T√©rminos de b√∫squeda: {terminos_busqueda}')

    parametros = doc.add_paragraph()
    parametros.alignment = WD_ALIGN_PARAGRAPH.CENTER
    if periodo_tiempo == 0:
        parametros.add_run('Mostrando noticias del d√≠a actual')
    else:
        parametros.add_run(f'Mostrando noticias de los √∫ltimos {periodo_tiempo} d√≠as')

    doc.add_paragraph('\n')

    for idx, noticia in enumerate(df_noticias.itertuples(), 1):
        num_noticia = doc.add_heading(f'Noticia {idx}', level=1)
        num_noticia.style.font.color.rgb = RGBColor(54, 96, 146)

        fecha = doc.add_paragraph()
        fecha_run = fecha.add_run('Fecha: ')
        fecha_run.bold = True
        fecha.add_run(noticia.Fecha)

        titulo_parrafo = doc.add_paragraph()
        titulo_parrafo.add_run('T√≠tulo: ').bold = True
        agregar_hiperv√≠nculo(titulo_parrafo, noticia.Enlace, noticia.T√≠tulo)

        doc.add_paragraph('_' * 50)
        doc.add_paragraph('\n')

    resumen = doc.add_paragraph()
    resumen.alignment = WD_ALIGN_PARAGRAPH.CENTER
    resumen_run = resumen.add_run(f'Total de noticias encontradas: {len(df_noticias)}')
    resumen_run.bold = True

    nota = doc.add_paragraph()
    nota.alignment = WD_ALIGN_PARAGRAPH.CENTER
    nota_run = nota.add_run('Nota: Haga clic en los t√≠tulos para abrir las noticias en su navegador')
    nota_run.italic = True

    # Guardar en BytesIO en lugar de archivo
    doc_io = BytesIO()
    doc.save(doc_io)
    doc_io.seek(0)
    return doc_io

def preparar_busqueda(tema):
    tema = re.sub(r'[^\w\s√°√©√≠√≥√∫√Å√â√ç√ì√ö√±√ë]', ' ', tema)
    tema = ' '.join(tema.split())

    tema_encoded = urllib.parse.quote(tema)
    terminos = '+'.join(tema.split())
    terminos_encoded = urllib.parse.quote(terminos)

    if len(tema.split()) > 1:
        terminos_exactos = f'"{tema_encoded}"'
    else:
        terminos_exactos = tema_encoded

    return terminos_encoded, terminos_exactos, tema

def buscar_noticias(tema, num_noticias, periodo_tiempo):
    terminos_encoded, terminos_exactos, tema_original = preparar_busqueda(tema)

    if periodo_tiempo == 0:
        base_url = 'https://news.google.com/rss/search?q='
        urls = [
            f'{base_url}{terminos_exactos}+when:1d&hl=es-419&gl=MX&ceid=MX:es-419',
            f'{base_url}{terminos_encoded}+when:1d&hl=es-419&gl=MX&ceid=MX:es-419'
        ]
        fecha_limite = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
    else:
        base_url = 'https://news.google.com/rss/search?q='
        urls = [
            f'{base_url}{terminos_exactos}+when:{periodo_tiempo}d&hl=es-419&gl=MX&ceid=MX:es-419',
            f'{base_url}{terminos_encoded}+when:{periodo_tiempo}d&hl=es-419&gl=MX&ceid=MX:es-419'
        ]
        fecha_limite = datetime.now() - timedelta(days=periodo_tiempo)

    todas_noticias = []

    for url in urls:
        try:
            feed = feedparser.parse(url)
            for entrada in feed.entries:
                try:
                    fecha_pub = datetime.strptime(entrada.published, '%a, %d %b %Y %H:%M:%S %Z')
                    if fecha_pub >= fecha_limite:
                        noticia = {
                            'T√≠tulo': limpiar_texto(entrada.title),
                            'Fecha': fecha_pub.strftime('%Y-%m-%d %H:%M'),
                            'Enlace': entrada.link,
                            'FechaOrd': fecha_pub
                        }
                        if not any(n['T√≠tulo'] == noticia['T√≠tulo'] for n in todas_noticias):
                            todas_noticias.append(noticia)
                except Exception:
                    continue
        except Exception as e:
            st.error(f"Error al procesar URL: {str(e)}")
            continue

    df_noticias = pd.DataFrame(todas_noticias)
    if not df_noticias.empty:
        df_noticias = df_noticias.sort_values('FechaOrd', ascending=False)
        df_noticias = df_noticias.drop('FechaOrd', axis=1)
        df_noticias = df_noticias.head(num_noticias)

    return df_noticias, tema_original

# Interfaz de usuario con Streamlit
with st.form("busqueda_form"):
    col1, col2 = st.columns([2, 1])

    with col1:
        tema = st.text_input("Tema a buscar:", placeholder="Ingresa el tema de b√∫squeda")

    with col2:
        num_noticias = st.number_input("N√∫mero de noticias:", min_value=1, max_value=50, value=10)
        periodo_tiempo = st.number_input("Per√≠odo de tiempo (d√≠as):", min_value=0, max_value=30, value=1,
                                       help="0 para solo hoy, 1-30 para d√≠as anteriores")

    buscar = st.form_submit_button("Buscar Noticias")

if buscar and tema:
    with st.spinner('Buscando noticias...'):
        try:
            df_noticias, terminos_busqueda = buscar_noticias(tema, num_noticias, periodo_tiempo)

            if df_noticias.empty:
                st.warning("No se encontraron noticias para los criterios especificados.")
            else:
                st.success(f"Se encontraron {len(df_noticias)} noticias.")

                # Mostrar noticias en la interfaz
                st.subheader("Noticias encontradas:")
                for idx, noticia in df_noticias.iterrows():
                    with st.expander(f"{noticia['Fecha']} - {noticia['T√≠tulo']}"):
                        st.write(f"[Leer noticia completa]({noticia['Enlace']})")

                # Generar documento Word
                doc_io = crear_documento_word(df_noticias, tema, periodo_tiempo, terminos_busqueda)

                # Bot√≥n de descarga
                st.download_button(
                    label="üì• Descargar reporte en Word",
                    data=doc_io.getvalue(),
                    file_name=f"noticias_{tema.replace(' ', '_')}_{datetime.now().strftime('%Y%m%d_%H%M')}.docx",
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                )

        except Exception as e:
            st.error(f"Ocurri√≥ un error: {str(e)}")